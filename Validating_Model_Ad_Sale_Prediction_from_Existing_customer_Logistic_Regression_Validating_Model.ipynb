{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBilSykFCbaG8yeqF0dbjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ragulan-K/ML-Projects-24/blob/main/Validating_Model_Ad_Sale_Prediction_from_Existing_customer_Logistic_Regression_Validating_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "bHd0Ppt37ybK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dYbxc_K3-uU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #useful for loading the dataset\n",
        "import numpy as np #to perform array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Choose Dataset file from Local Directory"
      ],
      "metadata": {
        "id": "-yfVvARS72Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "i0XJY4gt77dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Dataset"
      ],
      "metadata": {
        "id": "-xbLGir679Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('DigitalAd_dataset.csv')"
      ],
      "metadata": {
        "id": "WJefOM6r8AFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize Dataset"
      ],
      "metadata": {
        "id": "m9wcJ1KT8CCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.shape)\n",
        "print(dataset.head(5))"
      ],
      "metadata": {
        "id": "KxvlvQr_8E6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Segregate Dataset into X(Input/IndependentVariable) & Y(Output/DependentVariable)"
      ],
      "metadata": {
        "id": "KbyMJNjN8JSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "X"
      ],
      "metadata": {
        "id": "JD70i5L68LuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = dataset.iloc[:, -1].values\n",
        "Y"
      ],
      "metadata": {
        "id": "6sz-cEV88PJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting Dataset into Train & Test"
      ],
      "metadata": {
        "id": "LUcwXsaR8Q86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
      ],
      "metadata": {
        "id": "v-btNzb38T8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Scaling"
      ],
      "metadata": {
        "id": "Qfr_D5jp8WBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we scale our data to make all the features contribute equally to the result\n",
        "\n",
        "Fit_Transform - fit method is calculating the mean and variance of each of the features present in our data\n",
        "\n",
        "Transform - Transform method is transforming all the features using the respective mean and variance,\n",
        "\n",
        "We want our test data to be a completely new and a surprise set for our model"
      ],
      "metadata": {
        "id": "WqAaipnW8XjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "iNZc4H2D8giq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "0sEyLdcR8iWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(random_state = 0)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nmG-OnsH8l4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction for all Test Data"
      ],
      "metadata": {
        "id": "lTzrOJg38oI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "Ogf_mE2I8sna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating Model"
      ],
      "metadata": {
        "id": "-b-WmQ_T8vf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix"
      ],
      "metadata": {
        "id": "2H50siiN8yRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "528DrJOM82_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Accuracy_Score"
      ],
      "metadata": {
        "id": "OJmZROmy85cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy: {0}%\".format(accuracy_score(y_test, y_pred)*100))"
      ],
      "metadata": {
        "id": "ExNw35y58-kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Receiver Operating Curve - ROC Curve"
      ],
      "metadata": {
        "id": "7yAoyo6b9A-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nsProbability = [0 for _ in range(len(y_test))]\n",
        "lsProbability = model.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lsProbability = lsProbability[:, 1]\n",
        "# calculate scores\n",
        "nsAUC = roc_auc_score(y_test, nsProbability)\n",
        "lrAUC = roc_auc_score(y_test, lsProbability)\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (nsAUC*100))\n",
        "print('Logistic Skill: ROC AUC=%.3f' % (lrAUC*100))\n",
        "# calculate roc curves\n",
        "nsFP, nsTP, _ = roc_curve(y_test, nsProbability)\n",
        "lrFP, lrTP, _ = roc_curve(y_test, lsProbability)\n",
        "# plot the roc curve for the model\n",
        "plt.plot(nsFP, nsTP, linestyle='--', label='No Skill')\n",
        "plt.plot(lrFP, lrTP, marker='*', label='Logistic')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UrlWIq_W9FYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross Validation Score"
      ],
      "metadata": {
        "id": "CVfxTAEH9Hvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, random_state=100)\n",
        "result = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"CROSS VALIDATION SCORE: %.2f%%\" % (result.mean()*100.0))"
      ],
      "metadata": {
        "id": "9wgDU-8u9Oxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stratifield K-fold Cross Validation"
      ],
      "metadata": {
        "id": "sXPU7YWv9SOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skfold = StratifiedKFold(n_splits=3, random_state=100)\n",
        "model_skfold = LogisticRegression()\n",
        "results_skfold = cross_val_score(model_skfold, X, Y, cv=skfold)\n",
        "print(\"STRATIFIELD K-FOLD SCORE: %.2f%%\" % (results_skfold.mean()*100.0))"
      ],
      "metadata": {
        "id": "EeYjF-RK9VwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cumulative Accuracy Profile (CAP) Curve"
      ],
      "metadata": {
        "id": "1OD5UHez9ZUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(y_test)\n",
        "print(total)\n",
        "class_1_count = np.sum(y_test)\n",
        "print(class_1_count)\n",
        "class_0_count = total - class_1_count\n",
        "plt.plot([0, total], [0, class_1_count], c = 'r', linestyle = '--', label = 'Random Model')\n",
        "\n",
        "plt.plot([0, class_1_count, total],\n",
        "         [0, class_1_count, class_1_count],\n",
        "         c = 'grey',\n",
        "         linewidth = 2,\n",
        "         label = 'Perfect Model')\n",
        "\n",
        "probs = model.predict_proba(X_test)\n",
        "probs = probs[:, 1]\n",
        "model_y = [y for _, y in sorted(zip(probs, y_test), reverse = True)]\n",
        "y_values = np.append([0], np.cumsum(model_y))\n",
        "x_values = np.arange(0, total + 1)\n",
        "\n",
        "plt.plot(x_values,\n",
        "         y_values,\n",
        "         c = 'b',\n",
        "         label = 'LR Classifier',\n",
        "         linewidth = 4)\n",
        "\n",
        "index = int((50*total / 100))\n",
        "\n",
        "## 50% Verticcal line from x-axis\n",
        "plt.plot([index, index], [0, y_values[index]], c ='g', linestyle = '--')\n",
        "\n",
        "## Horizontal line to y-axis from prediction model\n",
        "plt.plot([0, index], [y_values[index], y_values[index]], c = 'g', linestyle = '--')\n",
        "\n",
        "class_1_observed = y_values[index] * 100 / max(y_values)\n",
        "plt.xlabel('Total observations')\n",
        "plt.ylabel('Class 1 observations')\n",
        "plt.title('Cumulative Accuracy Profile')\n",
        "plt.legend(loc = 'lower right')"
      ],
      "metadata": {
        "id": "cYMXiEKd9cgD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}